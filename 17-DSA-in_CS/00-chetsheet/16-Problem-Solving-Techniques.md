## Problem Solving Techniques

”Problem Solving Techniques” is a topic that explore various methods used to solve problems in computing and mathematics. They are approaches and procedures that help in the systematic identification and resolution of complex issues. Some of these techniques include “Divide and Conquer” where a problem is split into subproblems to make it easier to solve, “Dynamic Programming” which solves problems by dividing them into smaller similar sub-problems and storing the solutions of these subproblems to avoid unnecessary calculations, “Greedy Algorithms” which make the globally optimal choice at each step, “Backtracking” is used when problem can be solved incrementally, “Branch and Bound” method is used for optimization problems. These techniques are designed to efficiently solve problems by significantly reducing the time and computational effort required.

## Brute Force

”Brute Force” is a straightforward method to solve problems. It involves trying every possible solution until the right one is found. This technique does not require any specific skills or knowledge and the approach is directly applied to the problem at hand. However, while it can be effective, it is not always efficient since it often requires a significant amount of time and resources to go through all potential solutions. In terms of computational problems, a brute force algorithm examines all possibilities one by one until a satisfactory solution is found. With growing complexity, the processing time of brute force solutions dramatically increases leading to combinatorial explosion. Brute force is a base for complex problem-solving algorithms which improve the time and space complexity by adding heuristics or rules of thumb.

## Greedy Algorithms

Greedy algorithms follow the problem-solving heuristic of making the locally optimal choice at each stage with the hope of finding a global optimum. They are used for optimization problems. An optimal solution is one where the value of the solution is either maximum or minimum. These algorithms work in a ” greedy” manner by choosing the best option at the current, disregarding any implications on the future steps. This can lead to solutions that are less optimal. Examples of problems solved by greedy algorithms are Kruskal’s minimal spanning tree algorithm, Dijkstra’s shortest path algorithm, and the Knapsack problem.